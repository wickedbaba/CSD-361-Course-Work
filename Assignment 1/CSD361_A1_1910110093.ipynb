{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75795d26",
   "metadata": {},
   "source": [
    "# Assignmnet 1\n",
    "\n",
    "Name - Aryaman Singh Rana \n",
    "\n",
    "Roll No. - 1910110093"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f44d698",
   "metadata": {},
   "source": [
    "#### Problem Statement -\n",
    "To construct a class conditional probability distribution for the three classes present in the Iris data set and find the average error rate.\n",
    "\n",
    "#### My solution-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d5a4f5",
   "metadata": {},
   "source": [
    "#### 1. Importing the necessary files-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f541d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8235f21b",
   "metadata": {},
   "source": [
    "#### 2. Loading the Iris data set provided -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b9d5ff9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3            4\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa\n",
       "5  5.4  3.9  1.7  0.4  Iris-setosa\n",
       "6  4.6  3.4  1.4  0.3  Iris-setosa\n",
       "7  5.0  3.4  1.5  0.2  Iris-setosa\n",
       "8  4.4  2.9  1.4  0.2  Iris-setosa\n",
       "9  4.9  3.1  1.5  0.1  Iris-setosa"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet = pd.read_csv('iris.data',header=None)\n",
    "dataSet.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d919ff9c",
   "metadata": {},
   "source": [
    "#### 2.1 Checking the data set provided -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c785d113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4\n",
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " dataSet.groupby(4).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bae0fb3",
   "metadata": {},
   "source": [
    "We see that the given 3 class are equal in number.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b873d9",
   "metadata": {},
   "source": [
    "#### 3.0 Seperating the data into independent varible and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dc14f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X being the dependent variable and y being the independent variable\n",
    "X = dataSet.iloc[:,:-1].values\n",
    "y = dataSet.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a731f12",
   "metadata": {},
   "source": [
    "#### 3.1 Spliting the data into training set and test set -\n",
    "\n",
    "|S No.|Training set|Test set|\n",
    "|---|---|---\n",
    "|1|80%|20%|\n",
    "|2|70%|30%|\n",
    "|3|60%|40%|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "82366778",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X,y, train_size = 0.8, test_size = 0.2)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X,y, train_size = 0.7, test_size = 0.3)\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X,y, train_size = 0.6, test_size = 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090edca6",
   "metadata": {},
   "source": [
    "#### 4.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad114e18",
   "metadata": {},
   "source": [
    "Using GridSearchCV to find the bandwidth and the kernel type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "207f1519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wickedbaba\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [ -87.27704334          -inf          -inf  -45.62634809          -inf\n",
      "           nan  -60.22693687          -inf          -inf  -49.27254821\n",
      "          -inf           nan  -49.12397756          -inf          -inf\n",
      "  -55.46317837          -inf           nan  -47.21671538          -inf\n",
      "          -inf  -63.7600421           -inf           nan  -50.85228597\n",
      "          -inf          -inf  -73.8728822           -inf           nan\n",
      "  -58.22404781          -inf          -inf  -85.58774128          -inf\n",
      "           nan  -68.36951668          -inf          -inf  -98.72641865\n",
      "          -inf           nan  -80.7518844           -inf          -inf\n",
      " -113.12149672          -inf           nan  -95.05741442          -inf\n",
      "          -inf -128.59906205          -inf           nan -110.9958183\n",
      "  -68.40906889  -60.38436548 -144.97889234  -58.7323908            nan\n",
      " -128.19040804  -82.39281992  -71.07890762 -162.09951503  -68.75996229\n",
      "           nan -146.16674919  -98.70337864  -84.88963075 -179.85065316\n",
      "  -81.89267756           nan -164.51463742 -117.76600199 -101.00680875\n",
      " -198.18330548  -97.21225957           nan -183.18647557 -137.21921688\n",
      " -118.84232078 -217.08889686 -114.20932273           nan -202.4720836\n",
      " -156.19142397 -137.43910783 -236.56674178 -132.11625877           nan\n",
      " -222.62367723 -174.02481351 -156.0221483  -256.60165782 -150.32746353\n",
      "           nan -243.65246839 -192.10691224 -174.23548433 -277.15786625\n",
      " -168.45034309           nan -265.40321595 -212.9983629  -193.03743689\n",
      " -298.18352772 -187.01984708           nan -287.68060528 -236.09144281\n",
      " -213.53288124 -319.61863395 -206.85612609           nan -310.31642704\n",
      " -259.35967111 -235.25516445 -341.40199482 -227.75129275           nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\wickedbaba\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:929: RuntimeWarning: invalid value encountered in subtract\n",
      "  array_stds = np.sqrt(np.average((array -\n",
      "C:\\Users\\wickedbaba\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [ -80.91925239          -inf          -inf  -41.03645576          -inf\n",
      "           nan  -54.0826836           -inf          -inf  -43.5613813\n",
      "          -inf           nan  -42.64104242          -inf          -inf\n",
      "  -48.62261748          -inf           nan  -40.38411325          -inf\n",
      "          -inf  -55.71594723          -inf           nan  -43.68730258\n",
      "          -inf          -inf  -64.49342193          -inf           nan\n",
      "  -50.47506108          -inf          -inf  -74.71312175          -inf\n",
      "           nan  -59.60906755          -inf          -inf  -86.19774742\n",
      "          -inf           nan  -70.57422635          -inf          -inf\n",
      "  -98.79788004          -inf           nan  -83.14060118          -inf\n",
      "          -inf -112.36221325          -inf           nan  -97.0934761\n",
      "          -inf          -inf -126.72977336          -inf           nan\n",
      " -112.14975292  -72.40734558  -62.24834091 -141.7512827   -60.15372859\n",
      "           nan -127.90564767  -86.86892919  -74.45102099 -157.32141123\n",
      "  -71.75200582           nan -143.9872128  -103.19409227  -88.55258973\n",
      " -173.3917208   -85.1562441            nan -160.34568544 -120.00965355\n",
      " -103.98066146 -189.95352736  -99.88685402           nan -177.23005402\n",
      " -136.88078265 -120.32080039 -207.00782105 -115.59438536           nan\n",
      " -194.85840861 -152.40770334 -136.58284954 -224.54370945 -131.54921484\n",
      "           nan -213.24601872 -168.22012423 -152.52488501 -242.53201105\n",
      " -147.4290656            nan -232.26398983 -186.55243842 -169.0386343\n",
      " -260.92892806 -163.7311832            nan -251.74506619 -206.58001246\n",
      " -186.9180227  -279.68299533 -181.05977733           nan -271.54289882\n",
      " -226.93971223 -205.89014533 -298.74132273 -199.32089508           nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wickedbaba\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:929: RuntimeWarning: invalid value encountered in subtract\n",
      "  array_stds = np.sqrt(np.average((array -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "-------------------------\n",
      "{'bandwidth': 0.1, 'kernel': 'exponential'}\n",
      "{'bandwidth': 0.20691380811147897, 'kernel': 'gaussian'}\n",
      "{'bandwidth': 0.1, 'kernel': 'exponential'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wickedbaba\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [ -79.50959782          -inf          -inf  -37.48552129          -inf\n",
      "           nan  -52.77195971          -inf          -inf  -39.45985268\n",
      "          -inf           nan  -40.8987188           -inf          -inf\n",
      "  -43.6667753           -inf           nan  -37.8389009           -inf\n",
      "          -inf  -49.62103079          -inf           nan  -40.02213139\n",
      "          -inf          -inf  -57.00266973          -inf           nan\n",
      "  -45.3970071           -inf          -inf  -65.61049533          -inf\n",
      "           nan  -52.87341864          -inf          -inf  -75.30420201\n",
      "          -inf           nan  -61.96032032          -inf          -inf\n",
      "  -85.95793995          -inf           nan  -72.47959288          -inf\n",
      "          -inf  -97.43773247          -inf           nan  -84.26419753\n",
      "          -inf          -inf -109.60432291          -inf           nan\n",
      "  -97.01533131  -63.36274241  -54.95045952 -122.33473604  -53.23286624\n",
      "           nan -110.3454934   -74.91984038  -64.96266613 -135.54590602\n",
      "  -62.77934082           nan -123.96141354  -89.15646502  -76.79348636\n",
      " -149.20101484  -74.00677189           nan -137.84665106 -103.67460278\n",
      "  -89.98818514 -163.29375318  -86.56879668           nan -152.20845333\n",
      " -117.48013906 -103.84275146 -177.82406737  -99.90610662           nan\n",
      " -167.22852008 -130.78782997 -117.49955554 -192.7811196  -113.33572274\n",
      "           nan -182.92072081 -144.2991697  -131.04575277 -208.13833578\n",
      " -126.80360134           nan -199.17321061 -159.97099237 -145.1347357\n",
      " -223.85663193 -140.69032046           nan -215.83859466 -177.0685821\n",
      " -160.3569961  -239.89038066 -155.44059253           nan -232.78693318\n",
      " -194.51975334 -176.5587472  -256.1928018  -171.02285908           nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\wickedbaba\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:929: RuntimeWarning: invalid value encountered in subtract\n",
      "  array_stds = np.sqrt(np.average((array -\n"
     ]
    }
   ],
   "source": [
    "parameters = {'kernel':['gaussian','tophat','epanechnikov','exponential','linear','cosine'],'bandwidth' :np.logspace(-1,1,20)}\n",
    "\n",
    "# for ratio 80%-20%\n",
    "gsVar1 = GridSearchCV(KernelDensity(),parameters)\n",
    "gsVar1.fit(X_train1)\n",
    "dictionary1 = gsVar1.best_params_\n",
    "print(\"-------------------------\")\n",
    "\n",
    "# for ratio 70%-30%\n",
    "gsVar2 = GridSearchCV(KernelDensity(),parameters)\n",
    "gsVar2.fit(X_train2)\n",
    "dictionary2 = gsVar2.best_params_\n",
    "print(\"-------------------------\")\n",
    "\n",
    "# for ratio 60%-40%\n",
    "gsVar3 = GridSearchCV(KernelDensity(),parameters)\n",
    "gsVar3.fit(X_train3)\n",
    "dictionary3 = gsVar3.best_params_\n",
    "print(\"-------------------------\")\n",
    "\n",
    "print(dictionary1)\n",
    "print(dictionary2)\n",
    "print(dictionary3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67875cd",
   "metadata": {},
   "source": [
    "#### 4.1 I take the given bandwidth and kernel value and use it to find the Kernel density on the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b91481da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-48.80371994]\n",
      "[-12.35349601]\n",
      "[0.81782054]\n",
      "------------------\n",
      "[-209.74427242]\n",
      "[-9.69900527]\n",
      "[-0.27324078]\n",
      "------------------\n",
      "[-29.24049822]\n",
      "[-5.46324114]\n",
      "[1.00217083]\n"
     ]
    }
   ],
   "source": [
    "labelArray = ['Iris-setosa','Iris-versicolor','Iris-virginica']\n",
    "kdArray1 = []\n",
    "kdArray2 = []\n",
    "kdArray3 = []\n",
    "\n",
    "for element in labelArray:\n",
    "    # for ratio 1\n",
    "    kd1 = KernelDensity(kernel = dictionary1['kernel'],bandwidth = dictionary1['bandwidth']).fit(X_train1[y_train1 == element])\n",
    "    kdArray1.append(kd1)\n",
    "    \n",
    "    # for ratio 2\n",
    "    kd2 = KernelDensity(kernel = dictionary2['kernel'],bandwidth = dictionary2['bandwidth']).fit(X_train2[y_train2 == element])\n",
    "    kdArray2.append(kd2)\n",
    "    \n",
    "    # for ratio 3\n",
    "    kd3 = KernelDensity(kernel = dictionary3['kernel'],bandwidth = dictionary3['bandwidth']).fit(X_train3[y_train3 == element])\n",
    "    kdArray3.append(kd3)\n",
    "\n",
    "# checking the score samples\n",
    "for element in kdArray1:\n",
    "    print(element.score_samples([X_train1[0]]))\n",
    "\n",
    "print('------------------')\n",
    "\n",
    "for element in kdArray2:\n",
    "    print(element.score_samples([X_train2[0]]))\n",
    "\n",
    "print('------------------')\n",
    "\n",
    "for element in kdArray3:\n",
    "    print(element.score_samples([X_train3[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ca226d",
   "metadata": {},
   "source": [
    "#### 4.2 Now I make a prediction matrix which will be used to compare with the testing data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0a2da485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "45\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# for ratio 80%-20%\n",
    "prediction1 = []\n",
    "\n",
    "for i in range(len(X_test1)):\n",
    "    setosa = kdArray1[0].score_samples([X_test1[i]])\n",
    "    versi =  kdArray1[1].score_samples([X_test1[i]]) \n",
    "    virgi =  kdArray1[2].score_samples([X_test1[i]]) \n",
    "    \n",
    "    if(setosa > versi):\n",
    "        if(setosa > virgi):\n",
    "            prediction1.append(labelArray[0])\n",
    "            \n",
    "        else:\n",
    "            prediction1.append(labelArray[2])\n",
    "    else:\n",
    "        if(versi>virgi):\n",
    "            prediction1.append(labelArray[1])\n",
    "        else:\n",
    "            prediction1.append(labelArray[2])\n",
    "            \n",
    "\n",
    "# for ratio 70%-30%\n",
    "prediction2 = []\n",
    "\n",
    "for i in range(len(X_test2)):\n",
    "    setosa =  kdArray2[0].score_samples([X_test2[i]])\n",
    "    versi = kdArray2[1].score_samples([X_test2[i]]) \n",
    "    virgi = kdArray2[2].score_samples([X_test2[i]]) \n",
    "    \n",
    "    if(setosa > versi):\n",
    "        if(setosa > virgi):\n",
    "            prediction2.append(labelArray[0])\n",
    "            \n",
    "        else:\n",
    "            prediction2.append(labelArray[2])\n",
    "    else:\n",
    "        if(versi > virgi):\n",
    "            prediction2.append(labelArray[1])\n",
    "        else:\n",
    "            prediction2.append(labelArray[2])\n",
    "            \n",
    "            \n",
    "# for ratio 60%-40%\n",
    "prediction3 = []\n",
    "\n",
    "for i in range(len(X_test3)):\n",
    "    setosa = kdArray3[0].score_samples([X_test3[i]])\n",
    "    versi = kdArray3[1].score_samples([X_test3[i]]) \n",
    "    virgi = kdArray3[2].score_samples([X_test3[i]]) \n",
    "    \n",
    "    if(setosa > versi):\n",
    "        if(setosa > virgi):\n",
    "            prediction3.append(labelArray[0])\n",
    "            \n",
    "        else:\n",
    "            prediction3.append(labelArray[2])\n",
    "    else:\n",
    "        if(versi > virgi):\n",
    "            prediction3.append(labelArray[1])\n",
    "        else:\n",
    "            prediction3.append(labelArray[2])\n",
    "            \n",
    "print(len(prediction1))\n",
    "print(len(prediction2))\n",
    "print(len(prediction3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de05814d",
   "metadata": {},
   "source": [
    "The length confirms that the program is outputting the right ammount of labels required per every ratio fed to it.\n",
    "\n",
    "#### 4.3 Now I compare these prediciton matrix with y_test to find the error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1fe6ffde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error of ratio 80%-20% -  0.0 %\n",
      "The error of ratio 70%-30% -  6.666666666666667 %\n",
      "The error of ratio 60%-40% -  3.3333333333333335 %\n",
      "\n",
      "Average error 3.3333333333333335 %\n"
     ]
    }
   ],
   "source": [
    "negative1 = 0\n",
    "negative2 = 0\n",
    "negative3 = 0\n",
    "testLen1 = len(y_test1)\n",
    "testLen2 = len(y_test2)\n",
    "testLen3 = len(y_test3)\n",
    "\n",
    "for i in range(len(y_test1)):\n",
    "    if(prediction1[i] == y_test1[i]):\n",
    "        negative1+=1\n",
    "\n",
    "for i in range(len(y_test2)):\n",
    "    if(prediction2[i] == y_test2[i]):\n",
    "        negative2+=1\n",
    "\n",
    "for i in range(len(y_test3)):\n",
    "    if(prediction3[i] == y_test3[i]):\n",
    "        negative3+=1\n",
    "        \n",
    "\n",
    "error1 = ((testLen1-negative1)/testLen1)*100\n",
    "print(\"The error of ratio 80%-20% - \",error1 ,\"%\")\n",
    "\n",
    "error2 = ((testLen2-negative2)/testLen2)*100\n",
    "print(\"The error of ratio 70%-30% - \",error2 ,\"%\")\n",
    "\n",
    "error3 = ((testLen3-negative3)/testLen3)*100\n",
    "print(\"The error of ratio 60%-40% - \",error3 ,\"%\")\n",
    "\n",
    "print()\n",
    "average = (error1 + error2 + error3 )/3\n",
    "print(\"Average error\",average,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368acc79",
   "metadata": {},
   "source": [
    "#### 4.4 Now, I ran these test 10 times with different seed values and recorded the follwoing error values -\n",
    "\n",
    "|Test No.|Error in Ratios -|80%-20%|70%-30%|60%-40%|Average -|\n",
    "|---|---|---|---|---|---|\n",
    "|1||3.33%|2.22%|5.0%|3.518%|\n",
    "|2||3.33%|2.22%|1.66%|2.407%|\n",
    "|3||3.33%|2.22%|5.0%|3.518%|\n",
    "|4||0.0%|4.44%|5.0%|3.148%|\n",
    "|5||3.33%|0.0%|3.33%|2.22%|\n",
    "|6||3.33%|4.44%|5.0%|4.259%|\n",
    "|7||3.33%|2.22%|3.33%|2.96%|\n",
    "|8||6.66%|4.44%|1.66%|4.259%|\n",
    "|9||3.33%|4.44%|5.0%|4.25%|\n",
    "|10||3.33%|2.22%|1.66%|2.40%|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7911bc37",
   "metadata": {},
   "source": [
    "#### 5.0  Taking the average error -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ad8f248e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net AVG Error =  3.2599999999999993 %\n"
     ]
    }
   ],
   "source": [
    "avg = (3.5 + 2.4+3.5+3.1+2.2+4.2+2.9+4.2+4.2+2.4)/10\n",
    "\n",
    "print(\"Net AVG Error = \",avg,\"%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b5f119",
   "metadata": {},
   "source": [
    "#### In online sources the average error rate comes out to be 2%-3% and the aforementioned average error is near to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11491f4",
   "metadata": {},
   "source": [
    "#### 6.0 Conclusion -\n",
    "\n",
    "1. With the given data set size of 150 entries with 4 independent variable and 1 independent variable, the whole program ran in under 3 sec, giving an average error rate of 3.25%.  This is given the fact that I have an 8Gb RAM and an Intel i7 processor. \n",
    "\n",
    "\n",
    "2. When we go on to increase the size of the data set, not only does its time complexity increases but also the space complexity increases.<br>\n",
    "\n",
    "     _Take the example of_ **train_test_split** - The actual time complexity of **train_test_split** is O(n). But, if the data set is large, the machine has to access a lot of memory locations, which creates a bottleneck based on data passing and retrieval. Usually, the machine can do 10^8 operations per sec. But this problem alone results in the program taking longer than usual. \n",
    "     \n",
    "\n",
    "3. Now, on the basis of above written program, **net time complexity** of this **BDR classifier** would be\n",
    "    **O(n*f)**. where f = number of features and n = dataset size.\n",
    "\n",
    "4. When we increase the number of attributes and feature vectors in the learning set, the time complexity of the BDR classifier **increases** - (as TC = O(n*f) and we are increasing the value of f) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
